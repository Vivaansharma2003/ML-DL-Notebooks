{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Convolutional Neural Networks (CNNs) & Hardware Acceleration\n",
       "\n",
       "**Session Topic:** Feature Extraction, CNN Architecture, and PyTorch CPU vs. GPU Performance.\n",
       "\n",
       "**Target Audience:** Professors and Instructors.\n",
       "\n",
       "**Objectives:**\n",
       "1.  **Intuition:** Understand how \"Convolutions\" extract features (like edges) from images.\n",
       "2.  **Implementation:** Build a CNN using the **PyTorch** framework.\n",
       "3.  **Acceleration:** Empirically demonstrate the speed difference between training/inference on a **CPU** vs. a **GPU**."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Environment Setup & PyTorch\n",
       "PyTorch is a leading deep learning library. Unlike Scikit-Learn, it is designed to run on GPUs."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Install PyTorch (Pre-installed in Google Colab, but good for reference)\n",
       "# !pip install torch torchvision numpy matplotlib\n",
       "\n",
       "import torch\n",
       "import torch.nn as nn\n",
       "import torch.optim as optim\n",
       "import torchvision\n",
       "import torchvision.transforms as transforms\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "import time\n",
       "\n",
       "print(f\"PyTorch Version: {torch.__version__}\")\n",
       "\n",
       "# Check for GPU\n",
       "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
       "device_cpu = torch.device(\"cpu\")\n",
       "\n",
       "print(f\"GPU Available? {torch.cuda.is_available()}\")\n",
       "if torch.cuda.is_available():\n",
       "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
       "else:\n",
       "    print(\"WARNING: No GPU detected. Go to Runtime > Change runtime type > Hardware accelerator > T4 GPU\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Feature Extraction Intuition (The \"Convolution\")\n",
       "\n",
       "Before training a massive network, let's understand what a CNN actually *does*.\n",
       "\n",
       "A **Convolution** involves sliding a small matrix (Kernel/Filter) over an image to detect specific patterns (Vertical lines, Horizontal lines, Curves).\n",
       "\n",
       "Below, we manually simulate a \"Vertical Edge Detector\" without any neural network training."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def apply_convolution(image, kernel):\n",
       "    \"\"\"\n",
       "    Simple manual 2D convolution operation.\n",
       "    \"\"\"\n",
       "    img_h, img_w = image.shape\n",
       "    k_h, k_w = kernel.shape\n",
       "    \n",
       "    # Output dimension (assuming valid padding)\n",
       "    out_h = img_h - k_h + 1\n",
       "    out_w = img_w - k_w + 1\n",
       "    \n",
       "    output = np.zeros((out_h, out_w))\n",
       "    \n",
       "    # Slide the kernel\n",
       "    for i in range(out_h):\n",
       "        for j in range(out_w):\n",
       "            # Extract region of interest (ROI)\n",
       "            roi = image[i:i+k_h, j:j+k_w]\n",
       "            # Element-wise multiplication and sum\n",
       "            output[i, j] = np.sum(roi * kernel)\n",
       "            \n",
       "    return output\n",
       "\n",
       "# 1. Create a synthetic image (Vertical stripes)\n",
       "image = np.zeros((10, 10))\n",
       "image[:, :5] = 10  # Left half is bright\n",
       "image[:, 5:] = 0   # Right half is dark\n",
       "\n",
       "# 2. Define a Vertical Edge Detection Filter\n",
       "# This filter highlights changes from bright to dark\n",
       "filter_vertical = np.array([\n",
       "    [1, 0, -1],\n",
       "    [1, 0, -1],\n",
       "    [1, 0, -1]\n",
       "])\n",
       "\n",
       "# 3. Apply Convolution\n",
       "feature_map = apply_convolution(image, filter_vertical)\n",
       "\n",
       "# 4. Visualize\n",
       "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
       "ax[0].imshow(image, cmap='gray'); ax[0].set_title(\"Original Image (Stripes)\")\n",
       "ax[1].imshow(filter_vertical, cmap='gray'); ax[1].set_title(\"Vertical Edge Filter\")\n",
       "ax[2].imshow(feature_map, cmap='gray'); ax[2].set_title(\"Feature Map (Edges Detected)\")\n",
       "plt.show()\n",
       "\n",
       "print(\"Notice how the output highlights exactly where the vertical transition happens.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Dataset Preparation (CIFAR-10)\n",
       "\n",
       "We will use **CIFAR-10**, a dataset of 60,000 32x32 color images in 10 classes (airplane, bird, cat, etc.)."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Pre-processing: Convert to Tensor and Normalize\n",
       "transform = transforms.Compose([\n",
       "    transforms.ToTensor(),\n",
       "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize RGB channels\n",
       "])\n",
       "\n",
       "batch_size = 64\n",
       "\n",
       "# Download Training Data\n",
       "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
       "                                        download=True, transform=transform)\n",
       "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
       "                                          shuffle=True, num_workers=2)\n",
       "\n",
       "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
       "\n",
       "print(f\"Training samples: {len(trainset)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Defining the CNN Architecture\n",
       "\n",
       "In PyTorch, we define networks as Classes inheriting from `nn.Module`.\n",
       "\n",
       "**Architecture:**\n",
       "1. **Conv1:** Extracts low-level features (edges, colors).\n",
       "2. **Pool:** Reduces image size (downsampling).\n",
       "3. **Conv2:** Extracts high-level features (shapes, patterns).\n",
       "4. **FC (Fully Connected):** Makes the final classification."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "class SimpleCNN(nn.Module):\n",
       "    def __init__(self):\n",
       "        super(SimpleCNN, self).__init__()\n",
       "        # Input: 3 channels (RGB), Output: 6 feature maps, Kernel: 5x5\n",
       "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
       "        self.pool = nn.MaxPool2d(2, 2)\n",
       "        \n",
       "        # Input: 6 channels, Output: 16 feature maps, Kernel: 5x5\n",
       "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
       "        \n",
       "        # Fully connected layers\n",
       "        # 16 * 5 * 5 is the size after pooling twice\n",
       "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
       "        self.fc2 = nn.Linear(120, 84)\n",
       "        self.fc3 = nn.Linear(84, 10) # 10 Output classes\n",
       "\n",
       "    def forward(self, x):\n",
       "        # Apply Conv1 -> ReLU -> Pool\n",
       "        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
       "        # Apply Conv2 -> ReLU -> Pool\n",
       "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
       "        \n",
       "        # Flatten the 3D tensor to 1D vector for FC layers\n",
       "        x = torch.flatten(x, 1)\n",
       "        \n",
       "        # Dense layers\n",
       "        x = torch.nn.functional.relu(self.fc1(x))\n",
       "        x = torch.nn.functional.relu(self.fc2(x))\n",
       "        x = self.fc3(x)\n",
       "        return x\n",
       "\n",
       "print(\"Model Architecture Defined.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Experiment: CPU vs. GPU Training Speed\n",
       "\n",
       "We will define a generic training function that can accept a device (`cpu` or `cuda`) and train the model for 1 epoch. We will measure the wall-clock time for each."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def train_model(device, epochs=1):\n",
       "    # 1. Instantiate Model and move to Device (CPU or GPU)\n",
       "    net = SimpleCNN().to(device)\n",
       "    \n",
       "    # 2. Define Loss and Optimizer\n",
       "    criterion = nn.CrossEntropyLoss()\n",
       "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
       "\n",
       "    print(f\"--- Starting Training on {device} ---\")\n",
       "    start_time = time.time()\n",
       "\n",
       "    for epoch in range(epochs):\n",
       "        running_loss = 0.0\n",
       "        \n",
       "        # Iterate over data batches\n",
       "        for i, data in enumerate(trainloader, 0):\n",
       "            inputs, labels = data\n",
       "            \n",
       "            # CRITICAL STEP: Move inputs/labels to the specific device\n",
       "            inputs, labels = inputs.to(device), labels.to(device)\n",
       "\n",
       "            # Zero the parameter gradients\n",
       "            optimizer.zero_grad()\n",
       "\n",
       "            # Forward + Backward + Optimize\n",
       "            outputs = net(inputs)\n",
       "            loss = criterion(outputs, labels)\n",
       "            loss.backward()\n",
       "            optimizer.step()\n",
       "\n",
       "    end_time = time.time()\n",
       "    duration = end_time - start_time\n",
       "    print(f\"Finished Training on {device}.\")\n",
       "    print(f\"Time Taken: {duration:.4f} seconds\")\n",
       "    return net, duration"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Run 1: CPU Training\n",
       "This simulates running Deep Learning on a standard laptop without a dedicated graphics card."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Train on CPU\n",
       "# Note: We are running only 1 Epoch because CPUs are slow!\n",
       "model_cpu, time_cpu = train_model(device_cpu, epochs=1)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Run 2: GPU Training\n",
       "This utilizes the parallel processing power of the GPU (e.g., NVIDIA T4 in Colab). Notice the `.to(device)` logic in the function above handling the data transfer."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if torch.cuda.is_available():\n",
       "    # Train on GPU\n",
       "    model_gpu, time_gpu = train_model(device_gpu, epochs=1)\n",
       "    \n",
       "    # Calculate Speedup\n",
       "    speedup = time_cpu / time_gpu\n",
       "    print(f\"\\nResult: GPU was {speedup:.2f}x faster than CPU for training.\")\n",
       "else:\n",
       "    print(\"Skipping GPU test (No GPU available).\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Inference Speed Test\n",
       "\n",
       "It's not just training; applying the model (inference) is also faster on GPU. This is critical for real-time applications (e.g., self-driving cars)."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def measure_inference(model, device, batches=50):\n",
       "    model.eval() # Set to evaluation mode\n",
       "    dataiter = iter(trainloader)\n",
       "    \n",
       "    start = time.time()\n",
       "    with torch.no_grad(): # No need to calculate gradients for inference\n",
       "        for i in range(batches):\n",
       "            images, labels = next(dataiter)\n",
       "            images = images.to(device)\n",
       "            _ = model(images)\n",
       "    end = time.time()\n",
       "    return end - start\n",
       "\n",
       "# Measure CPU Inference\n",
       "inf_time_cpu = measure_inference(model_cpu, device_cpu)\n",
       "print(f\"Inference time (50 batches) on CPU: {inf_time_cpu:.4f}s\")\n",
       "\n",
       "if torch.cuda.is_available():\n",
       "    # Measure GPU Inference\n",
       "    inf_time_gpu = measure_inference(model_gpu, device_gpu)\n",
       "    print(f\"Inference time (50 batches) on GPU: {inf_time_gpu:.4f}s\")\n",
       "    \n",
       "    print(f\"Inference Speedup: {inf_time_cpu/inf_time_gpu:.2f}x\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Conclusion\n",
       "\n",
       "1.  **Convolutions:** We saw how simple filters can detect edges in images.\n",
       "2.  **PyTorch:** We built a standard CNN Architecture (`Conv2d`, `MaxPool`, `Linear`).\n",
       "3.  **Acceleration:** \n",
       "    -   **Training:** GPUs offer massive speedups (often 10x-50x) by parallelizing the forward/backward passes.\n",
       "    -   **Inference:** Predicting on batches of data is also significantly faster on GPU.\n",
       "\n",
       "**Note:** For very small models or tiny batch sizes, the overhead of moving data to the GPU might outweigh the benefits. However, for modern deep learning (ResNet, Transformers), GPUs are mandatory."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }
   