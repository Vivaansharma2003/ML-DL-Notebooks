{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79052a16",
   "metadata": {},
   "source": [
    "## Day 3 - K Nearest Neighbour classification and Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e9b1be",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34d786",
   "metadata": {},
   "source": [
    "### 2. K Nearest Neighbour\n",
    "\n",
    "**K-Nearest Neighbors (KNN)** is a supervised learning algorithm that predicts the output of a data point based on the majority class or average value of its k closest neighbors.\n",
    "It is a non-parametric, distance-based method that works for both classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134767e",
   "metadata": {},
   "source": [
    "#### 2.1 Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38af20b",
   "metadata": {},
   "source": [
    "We have a dataset of Iris flowers with measurements for their petals and sepals.\n",
    "\n",
    "Our goal is to train a model that can identify the species of a new flower, Simply by measuring its dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c736e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                     # Import pandas for data handling\n",
    "from sklearn.datasets import load_iris  # Import function to load the iris dataset\n",
    "\n",
    "print(\"\\nLoading Iris Dataset...\")\n",
    "\n",
    "# Load the iris data from sklearn's built-in datasets\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame for easy data analysis and visualization\n",
    "# 'iris.data' contains the feature values, and 'iris.feature_names' are their column names\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Add a new column for the species as integer labels (0, 1, or 2)\n",
    "df['species_id'] = iris.target\n",
    "\n",
    "# Define a mapping from the species IDs to their actual names for better clarity\n",
    "species_map = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
    "\n",
    "# Map each species_id to its corresponding species name and add it as a new column\n",
    "df['species_name'] = df['species_id'].map(species_map)\n",
    "\n",
    "# Display the first five rows so you can see how the data looks\n",
    "print(\"First 5 rows of the Iris data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a2ab9",
   "metadata": {},
   "source": [
    "#### 2.2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style for better visibility\n",
    "plt.style.use('ggplot') \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "sns.scatterplot(data=df, x='sepal length (cm)', y='sepal width (cm)', \n",
    "                hue='species_name', s=100, palette='bright')\n",
    "plt.title(\"Iris Species Distribution: Sepal Dimensions\")\n",
    "plt.xlabel(\"Sepal Length (cm)\")\n",
    "plt.ylabel(\"Sepal Width (cm)\")\n",
    "plt.legend(title='Species')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7c8d7",
   "metadata": {},
   "source": [
    "#### 2.3 Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fded48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select sepal length and width as feature columns (X)\n",
    "X = df[['sepal length (cm)', 'sepal width (cm)']]\n",
    "\n",
    "# Select species name as label column (y)\n",
    "y = df['species_name']\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize the standard scaler for normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Use the same scaler to transform the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Show before and after scaling to verify\n",
    "print(\"\\nData Scaled.\")\n",
    "print(f\"Original Feature Example: \\n{X_train.iloc[0]}\")\n",
    "print(f\"Scaled Feature Example: {X_train_scaled[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d414fadf",
   "metadata": {},
   "source": [
    "#### 2.4 Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65018309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "k_value = 32\n",
    "knn = KNeighborsClassifier(n_neighbors=k_value)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nKNN Model trained with K={k_value}\")\n",
    "\n",
    "pred = knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "# Print additional metrics\n",
    "acc = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred, average='weighted')\n",
    "recall = recall_score(y_test, pred, average='weighted')\n",
    "f1 = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "print(f\"Precision (weighted): {precision:.4f}\")\n",
    "print(f\"Recall (weighted): {recall:.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442154dc",
   "metadata": {},
   "source": [
    "#### 2.5 Choosing the right K values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba592403",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "range_of_k = 35\n",
    "# Will check K values from 1 to 20\n",
    "for i in range(1, range_of_k):\n",
    "    knn_i = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_i.fit(X_train_scaled, y_train)\n",
    "    pred_i = knn_i.predict(X_test_scaled)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, range_of_k), error_rate, color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.xticks(range(1, range_of_k))\n",
    "print(\"\\nPlotting Error Rate... Look for the lowest error or the 'elbow'.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5cb1d",
   "metadata": {},
   "source": [
    "#### 2.6 New predictions\n",
    "\n",
    "Let's take some other values than the dataset and test what we actually get! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery_flower = [[5.1, 3.5]]\n",
    "mystery_scaled = scaler.transform(mystery_flower)\n",
    "\n",
    "prediction = knn.predict(mystery_scaled)\n",
    "print(f\"\\nMystery Flower Prediction (Dimensions: {mystery_flower[0]}):\")\n",
    "print(f\"The Model identifies this as: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551869d",
   "metadata": {},
   "source": [
    "### 3. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c219c2f",
   "metadata": {},
   "source": [
    "Topics: Information Gain, Gini Impurity, Non-Parametric Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf3edba",
   "metadata": {},
   "source": [
    "#### 3.1 Understanding Gini Index \n",
    "\n",
    "Gini Index measures node impurity by estimating how often a randomly chosen sample would be misclassified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_gini(labels):\n",
    "    # Gini = 1 - sum(probabilities^2)\n",
    "    # 0.0 = Perfect Purity (All same class)\n",
    "    # 0.5 = Max Impurity (50/50 split in binary)\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / len(labels)\n",
    "    gini = 1 - np.sum(probabilities ** 2)\n",
    "    return gini\n",
    "\n",
    "# Example: A crate with 5 bottles of Wine A and 5 of Wine B (High Impurity)\n",
    "mixed_crate = ['Wine A']*5 + ['Wine B']*5\n",
    "# Example: A crate with 10 bottles of Wine A (Pure)\n",
    "pure_crate = ['Wine A']*10\n",
    "\n",
    "print(f\"\\nPart 2: Decision Trees Started.\")\n",
    "print(f\"Gini of Mixed Crate (50/50): {calculate_gini(mixed_crate):.2f}\")\n",
    "print(f\"Gini of Pure Crate (100/0):  {calculate_gini(pure_crate):.2f}\")\n",
    "print(\"The Tree searches for splits that result in 'Pure Crates'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c424f0aa",
   "metadata": {},
   "source": [
    "#### 3.2 Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792a0569",
   "metadata": {},
   "source": [
    "We load the Wine dataset from Scikit-Learn.\n",
    "\n",
    "13 Features (Alcohol, Malic Acid, Ash, Alkalinity, etc.)\n",
    "\n",
    "Target: Cultivar Class (0, 1, or 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "df_wine = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "df_wine['target'] = wine.target\n",
    "\n",
    "print(\"\\n--- Wine Dataset Loaded ---\")\n",
    "print(f\"Features: {len(wine.feature_names)}\")\n",
    "print(f\"Target Classes: {wine.target_names}\")\n",
    "print(\"First 5 rows:\")\n",
    "print(df_wine.head())\n",
    "\n",
    "X_wine = df_wine[wine.feature_names]\n",
    "y_wine = df_wine['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_wine, y_wine, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993bc71",
   "metadata": {},
   "source": [
    "##### **MODEL 1: Gini impurity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ffa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "dt_gini.fit(X_train_w, y_train_w)\n",
    "\n",
    "print(\"\\nDecision Tree (Gini) Trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953ae27",
   "metadata": {},
   "source": [
    "#### 3.3 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c081b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plot_tree(dt_gini, \n",
    "          feature_names=wine.feature_names,  \n",
    "          class_names=wine.target_names,\n",
    "          filled=True, \n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title(\"Visualizing the Decision Tree Logic (Gini)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54836106",
   "metadata": {},
   "source": [
    "#### 3.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1016dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "pred_w = dt_gini.predict(X_test_w)\n",
    "acc = accuracy_score(y_test_w, pred_w)\n",
    "precision = precision_score(y_test_w, pred_w, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test_w, pred_w, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test_w, pred_w, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nModel Accuracy on Test Data: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_w, pred_w, target_names=wine.target_names, zero_division=0))\n",
    "\n",
    "# Predict for a single sample\n",
    "sample_wine = X_test_w.iloc[0].values.reshape(1, -1)\n",
    "prediction_code = dt_gini.predict(sample_wine)[0]\n",
    "prediction_label = wine.target_names[prediction_code]\n",
    "print(f\"Prediction for Sample Wine: {prediction_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c37a84",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
